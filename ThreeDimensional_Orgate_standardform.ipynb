{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import BootstrapFunctions as bsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List out the perturbation types: u is up, d is down, n is none. l for lambda, g for gamma.  Add 1,2 to balance the neutral points\n",
    "pertcases = {\"lngn\":[0,1,2],\"lngu\":[3,4,5],\"lngd\":[6,7,8],\n",
    "             \"lugn\":[9,10,11],\"lugu\":[12,13,14],\"lugd\":[15,16,17],\n",
    "             \"ldgn\":[18,19,20],\"ldgu\":[21,22,23],\"ldgd\":[24,25,26]}\n",
    "oneparamperts = pertcases[\"lngn\"]+pertcases[\"lugn\"]+pertcases[\"ldgn\"]+pertcases[\"lngu\"]+pertcases[\"lngd\"]\n",
    "no_nonperts = pertcases[\"lugn\"]+pertcases[\"ldgn\"]+pertcases[\"lngu\"]+pertcases[\"lngd\"]\n",
    "inv_pertcases = {v_int:k for k, v in pertcases.items() for v_int in v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramlist = ['lambda','beta_x','gamma','beta_y','alpha','beta_z','nx','Kx','ny','Ky','offset']\n",
    "byfilelist = ['fileN','fileda','filedb','sysname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_columns = ['E[rhoxy]','E[CVx/CVy]','E[<x>]','E[<y>]','E[<F_x>]','E[<F_y>]',\n",
    "                    '97.5% (rhoxy)','2.5% (rhoxy)','97.5% (CVx/CVy)','2.5% (CVx/CVy)',\n",
    "                    '97.5% (<x>)','2.5% (<x>)','97.5% (<y>)','2.5% (<y>)',\n",
    "                    '97.5% (<F_x>)','2.5% (<F_x>)','97.5% (<F_y>)','2.5% (<F_y>)',\n",
    "                    'F_y at avg','F_x at avg','Var[lambda]','Var[gamma]','E[lambda]','E[gamma]',\n",
    "                    'consistent fy signs (avg)','consistent fy signs (at avg)',\n",
    "                    'consistent fx signs (avg)','consistent fx signs (at avg)']\n",
    "parentfolders = ['IntHill','IntHill_consistent_violations_test*','IntHill_consistent_violator_1e8','IntHill_consistent_violator_largeN',\n",
    "                 'IntHill_neg1fxoverlineattempts','IntHill_randomstart','IntHill_randomstart_highfx','IntHill_randomstart_nofb','IntHill_Violator_largeN_plusbonus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate(x,y,alpha,nx,Kx,ny,Ky,o):\n",
    "    return alpha*(y**ny)/(Ky**ny+y**ny) + ((x**nx)/(Kx**nx+x**nx)) + o\n",
    "def rate_deriv_x(x,nx,Kx):\n",
    "    return nx*(x**(nx-1))*(Kx**nx)/(Kx**nx+x**nx)**2\n",
    "def rate_deriv_y(y,alpha,ny,Ky):\n",
    "    return alpha*ny*(y**(ny-1))*(Ky**ny)/(Ky**ny+y**ny)**2\n",
    "def sensitivty_x(x,y,alpha,nx,Kx,ny,Ky,o):\n",
    "    return x*rate_deriv_x(x,nx,Kx)/rate(x,y,alpha,nx,Kx,ny,Ky,o)\n",
    "def sensitivty_y(x,y,alpha,nx,Kx,ny,Ky,o):\n",
    "    return y*rate_deriv_y(y,alpha,ny,Ky)/rate(x,y,alpha,nx,Kx,ny,Ky,o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook used to generate data for alldots.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_feedback = []\n",
    "just_mrna_feedback = []\n",
    "just_protein_feedback = []\n",
    "both_feedback = []\n",
    "names = ['3Dno_feedback','3Djust_mrna_feedback','3Djust_protein_feedback','3Dboth_feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished IntHill\n",
      "Finished IntHill_consistent_violations_test*\n",
      "Finished IntHill_consistent_violator_1e8\n",
      "Finished IntHill_consistent_violator_largeN\n",
      "Finished IntHill_neg1fxoverlineattempts\n",
      "Finished IntHill_randomstart\n",
      "Finished IntHill_randomstart_highfx\n",
      "Finished IntHill_randomstart_nofb\n",
      "Finished IntHill_Violator_largeN_plusbonus\n"
     ]
    }
   ],
   "source": [
    "#For outputting the standard form of the data\n",
    "for parent in parentfolders:\n",
    "    folders = glob.glob(f'Data/{parent}/*/*')\n",
    "    dat = []\n",
    "    failedsims = []\n",
    "    bootstrapdicts = []\n",
    "    for i,folder in enumerate(folders):\n",
    "        files = glob.glob(folder+'/*data.csv',recursive=True)\n",
    "        for j,f in enumerate(files):\n",
    "            data = pd.read_csv(f)\n",
    "            data = data.reset_index().rename(columns={'index':'perturbation'})\n",
    "            numstrings = f.split(\"_\")[-2].split('n')\n",
    "            if (data[['Cov Bal xx','Cov Bal yy','Cov Bal xy','Cov Bal xz','Cov Bal yz','Cov Bal zz']] > 0.05).any(axis=1).any():\n",
    "                failedsims.append(f)\n",
    "                continue\n",
    "            if 'offset' not in data:\n",
    "                data['offset'] = 0\n",
    "            dat.append(data)\n",
    "            bsdict = bsf.pertexp_interpret(data,'all',analysed_columns=['<x>','<y>','<z>',\"<F_x>\",\"<F_y>\"])\n",
    "            fys = sensitivty_y(data['<x>'].astype(float),data['<y>'].astype(float),\n",
    "                                            data['alpha'],data['nx'].astype(float),data['Kx'],\n",
    "                                            data['ny'].astype(float),data['Ky'],data['offset'])\n",
    "            fxs = sensitivty_x(data['<x>'].astype(float),data['<y>'].astype(float),\n",
    "                                            data['alpha'],data['nx'].astype(float),data['Kx'],\n",
    "                                            data['ny'].astype(float),data['Ky'],data['offset'])\n",
    "            bsdict['F_y at avg'] = fys.mean()\n",
    "            bsdict['F_x at avg'] = fxs.mean()\n",
    "            bsdict['consistent fy signs (avg)'] = np.sum(np.sign(data['<F_y>']))\n",
    "            bsdict['consistent fx signs (avg)'] = np.sum(np.sign(1-data['<F_x>']))\n",
    "            bsdict['consistent fy signs (at avg)'] = np.sum(np.sign(fys))\n",
    "            bsdict['consistent fx signs (at avg)'] = np.sum(np.sign(1-fxs))\n",
    "            bsdict['fileN'] = float(numstrings[0])\n",
    "            bsdict['fileda'] = float(numstrings[1])\n",
    "            bsdict['filedb'] = float(numstrings[2])\n",
    "            bsdict['sysname'] = \"/\".join(f.split(\"/\")[:-1])\n",
    "            for p in paramlist:\n",
    "                try:\n",
    "                    bsdict[p] = data[p][0]\n",
    "                except KeyError:\n",
    "                    bsdict[p] = 0\n",
    "            if data['nx'][0] == 0 and data['ny'][0] == 0:\n",
    "                no_feedback.append(bsdict)\n",
    "            elif data['nx'][0] != 0 and data['ny'][0] == 0:\n",
    "                just_mrna_feedback.append(bsdict)\n",
    "            elif data['nx'][0] == 0 and data['ny'][0] != 0:\n",
    "                just_protein_feedback.append(bsdict)\n",
    "            else:\n",
    "                both_feedback.append(bsdict)\n",
    "    print(f\"Finished {parent}\")\n",
    "for i,dataset in enumerate([no_feedback,just_mrna_feedback,just_protein_feedback,both_feedback]):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.set_index(['fileN','fileda','filedb','sysname'],inplace=True)\n",
    "    df[paramlist+['E[<F_x>]','E[<F_y>]','F_y at avg','F_x at avg','consistent fy signs (avg)','consistent fx signs (avg)',\n",
    "                  'consistent fy signs (at avg)','consistent fx signs (at avg)']].to_csv(f'Data/parameters/{names[i]}.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#For outputting the standard form of the data\n",
    "for parent in parentfolders:\n",
    "    folders = glob.glob(f'Data/{parent}/*/*')\n",
    "    dat = []\n",
    "    failedsims = []\n",
    "    bootstrapdicts = []\n",
    "    for i,folder in enumerate(folders):\n",
    "        files = glob.glob(folder+'/*data.csv',recursive=True)\n",
    "        for j,f in enumerate(files):\n",
    "            data = pd.read_csv(f)\n",
    "            data = data.reset_index().rename(columns={'index':'perturbation'})\n",
    "            numstrings = f.split(\"_\")[-2].split('n')\n",
    "            if (data[['Cov Bal xx','Cov Bal yy','Cov Bal xy','Cov Bal xz','Cov Bal yz','Cov Bal zz']] > 0.05).any(axis=1).any():\n",
    "                failedsims.append(f)\n",
    "                continue\n",
    "            if 'offset' not in data:\n",
    "                data['offset'] = 0\n",
    "            dat.append(data)\n",
    "            bsdict = bsf.pertexp_interpret(data,'all',analysed_columns=['<x>','<y>','<z>',\"<F_x>\",\"<F_y>\"])\n",
    "            fys = sensitivty_y(data['<x>'].astype(float),data['<y>'].astype(float),\n",
    "                                            data['alpha'],data['nx'].astype(float),data['Kx'],\n",
    "                                            data['ny'].astype(float),data['Ky'],data['offset'])\n",
    "            fxs = sensitivty_x(data['<x>'].astype(float),data['<y>'].astype(float),\n",
    "                                            data['alpha'],data['nx'].astype(float),data['Kx'],\n",
    "                                            data['ny'].astype(float),data['Ky'],data['offset'])\n",
    "            bsdict['F_y at avg'] = fys.mean()\n",
    "            bsdict['F_x at avg'] = fxs.mean()\n",
    "            bsdict['consistent fy signs (avg)'] = np.sum(np.sign(data['<F_y>']))\n",
    "            bsdict['consistent fx signs (avg)'] = np.sum(np.sign(1-data['<F_x>']))\n",
    "            bsdict['consistent fy signs (at avg)'] = np.sum(np.sign(fys))\n",
    "            bsdict['consistent fx signs (at avg)'] = np.sum(np.sign(1-fxs))\n",
    "            bsdict['fileN'] = float(numstrings[0])\n",
    "            bsdict['fileda'] = float(numstrings[1])\n",
    "            bsdict['filedb'] = float(numstrings[2])\n",
    "            bsdict['sysname'] = \"/\".join(f.split(\"/\")[:-1])\n",
    "            for p in paramlist:\n",
    "                try:\n",
    "                    bsdict[p] = data[p][0]\n",
    "                except KeyError:\n",
    "                    bsdict[p] = 0\n",
    "            bootstrapdicts.append(bsdict)\n",
    "    directory = f\"/\".join(f.split(\"/\")[:-3])\n",
    "    bootstrapped_res = pd.DataFrame(bootstrapdicts)\n",
    "    bootstrapped_res.set_index([\"fileN\",'fileda','filedb','sysname'],inplace=True)\n",
    "    bootstrapped_res[standard_columns].to_csv(f'{directory}/{directory.split(\"/\")[-1]}_standard_form.csv')\n",
    "    print(f\"Finished {directory}\")\n",
    "    #with open(f'{directory}/{directory.split(\"/\")[-1]}_failedsims.txt','w') as f:\n",
    "    #    for path in failedsims:\n",
    "    #        f.write(f\"{path}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci_comp0624",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
