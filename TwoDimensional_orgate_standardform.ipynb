{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook used to generate data for alldots.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import BootstrapFunctions as bsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_columns = ['E[rhoxy]','E[CVx/CVy]','E[<x>]','E[<y>]','E[<F_x>]','E[<F_y>]',\n",
    "                    '97.5% (rhoxy)','2.5% (rhoxy)','97.5% (CVx/CVy)','2.5% (CVx/CVy)',\n",
    "                    '97.5% (<x>)','2.5% (<x>)','97.5% (<y>)','2.5% (<y>)',\n",
    "                    '97.5% (<F_x>)','2.5% (<F_x>)','97.5% (<F_y>)','2.5% (<F_y>)',\n",
    "                    'F_y at avg','F_x at avg','Var[lambda]','Var[gamma]','E[lambda]','E[gamma]',\n",
    "                    'consistent fy signs (avg)','consistent fy signs (at avg)',\n",
    "                    'consistent fx signs (avg)','consistent fx signs (at avg)']\n",
    "parentfolders = ['BothFb','BothFb_fasty','BothFb_hardcoded','BothFb_Nothardcoded','BothFb_Nothardcoded_allfb',\n",
    "                 'BothFb_Nothardcoded_fxlt1test','Bothfb_Violator_aboveline_largeN_plusbonus',\n",
    "                 'fx_violations_withpdist','NegFy1','NegFy2','NegFylt1','NoFb','PosFy1']\n",
    "#parentfolders = ['NoFb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramlist = ['lambda','beta_x','gamma','beta_y','nx','Kx','ny','Ky','offset']\n",
    "byfilelist = ['fileN','fileda','filedb','sysname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List out the perturbation types: u is up, d is down, n is none. l for lambda, g for gamma.  Add 1,2 to balance the neutral points\n",
    "pertcases = {\"lngn\":[0,1,2],\"lngu\":[3,4,5],\"lngd\":[6,7,8],\n",
    "             \"lugn\":[9,10,11],\"lugu\":[12,13,14],\"lugd\":[15,16,17],\n",
    "             \"ldgn\":[18,19,20],\"ldgu\":[21,22,23],\"ldgd\":[24,25,26]}\n",
    "oneparamperts = pertcases[\"lngn\"]+pertcases[\"lugn\"]+pertcases[\"ldgn\"]+pertcases[\"lngu\"]+pertcases[\"lngd\"]\n",
    "no_nonperts = pertcases[\"lugn\"]+pertcases[\"ldgn\"]+pertcases[\"lngu\"]+pertcases[\"lngd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate(x,y,l,nx,Kx,ny,Ky,o):\n",
    "    return l*((x**nx)/(Kx**nx+x**nx) + (y**ny)/(Ky**ny+y**ny) + o)\n",
    "def rate_deriv_x(x,y,l,nx,Kx,ny,Ky,o):\n",
    "    return l*nx*(x**(nx-1))*(Kx**nx)/(Kx**nx+x**nx)**2\n",
    "def rate_deriv_y(x,y,l,nx,Kx,ny,Ky,o):\n",
    "    return l*ny*(y**(ny-1))*(Ky**ny)/(Ky**ny+y**ny)**2\n",
    "def sensitivty_x(x,y,l,nx,Kx,ny,Ky,o):\n",
    "    return x*rate_deriv_x(x,y,l,nx,Kx,ny,Ky,o)/rate(x,y,l,nx,Kx,ny,Ky,o)\n",
    "def sensitivty_y(x,y,l,nx,Kx,ny,Ky,o):\n",
    "    return y*rate_deriv_y(x,y,l,nx,Kx,ny,Ky,o)/rate(x,y,l,nx,Kx,ny,Ky,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_feedback_no_int = []\n",
    "just_mrna_feedback = []\n",
    "just_protein_feedback = []\n",
    "both_feedback = []\n",
    "names = ['2D_no_feedback_no_int','2D_just_mrna_feedback','2D_just_protein_feedback','2D_both_feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished BothFb\n",
      "Finished BothFb_fasty\n",
      "Finished BothFb_hardcoded\n",
      "Finished BothFb_Nothardcoded\n",
      "Finished BothFb_Nothardcoded_allfb\n",
      "Finished BothFb_Nothardcoded_fxlt1test\n",
      "Finished Bothfb_Violator_aboveline_largeN_plusbonus\n",
      "Finished fx_violations_withpdist\n",
      "Finished NegFy1\n",
      "Finished NegFy2\n",
      "Finished NegFylt1\n",
      "Finished NoFb\n",
      "Finished PosFy1\n"
     ]
    }
   ],
   "source": [
    "#For sorting data to display parameters\n",
    "for parent in parentfolders:\n",
    "    folders = glob.glob(f'Data/{parent}/*/*')\n",
    "    dat = []\n",
    "    failedsims = []\n",
    "    bootstrapdicts = []\n",
    "    for i,folder in enumerate(folders):\n",
    "        files = glob.glob(folder+'/*data.csv',recursive=True)\n",
    "        for j,f in enumerate(files):\n",
    "            data = pd.read_csv(f)\n",
    "            data = data.reset_index().rename(columns={'index':'perturbation'})\n",
    "            numstrings = f.split(\"_\")[-2].split('n')\n",
    "            if (data[['Cov Bal xx','Cov Bal yy','Cov Bal xy']] > 0.05).any(axis=1).any():\n",
    "                failedsims.append(f)\n",
    "                continue\n",
    "            data['fileN'] = float(numstrings[0])\n",
    "            data['fileda'] = float(numstrings[1])\n",
    "            data['filedb'] = float(numstrings[2])\n",
    "            data['sysname'] = \"/\".join(f.split(\"/\")[:-1])\n",
    "            if 'offset' not in data:\n",
    "                data['offset'] = 0\n",
    "            dat.append(data)\n",
    "            bsdict = bsf.pertexp_interpret(data,'all')\n",
    "            fys = sensitivty_y(data['<x>'].astype(float),data['<y>'].astype(float),\n",
    "                                            data['lambda'],data['nx'].astype(float),data['Kx'],\n",
    "                                            data['ny'].astype(float),data['Ky'],data['offset'])\n",
    "            fxs = sensitivty_x(data['<x>'].astype(float),data['<y>'].astype(float),\n",
    "                                            data['lambda'],data['nx'].astype(float),data['Kx'],\n",
    "                                            data['ny'].astype(float),data['Ky'],data['offset'])\n",
    "            bsdict['F_y at avg'] = fys.mean()\n",
    "            bsdict['F_x at avg'] = fxs.mean()\n",
    "            bsdict['consistent fy signs (avg)'] = np.sum(np.sign(data['<F_y>']))\n",
    "            bsdict['consistent fx signs (avg)'] = np.sum(np.sign(1-data['<F_x>']))\n",
    "            bsdict['consistent fy signs (at avg)'] = np.sum(np.sign(fys))\n",
    "            bsdict['consistent fx signs (at avg)'] = np.sum(np.sign(1-fxs))\n",
    "            bsdict['fileN'] = float(numstrings[0])\n",
    "            bsdict['fileda'] = float(numstrings[1])\n",
    "            bsdict['filedb'] = float(numstrings[2])\n",
    "            bsdict['sysname'] = \"/\".join(f.split(\"/\")[:-1])\n",
    "            for p in paramlist:\n",
    "                try:\n",
    "                    bsdict[p] = data[p][0]\n",
    "                except KeyError:\n",
    "                    bsdict[p] = 0\n",
    "            if data['nx'][0] == 0 and data['ny'][0] == 0:\n",
    "                if bsdict['offset'] != 0:\n",
    "                    bsdict['lambda'] *= bsdict['offset']\n",
    "                    bsdict['offset'] = 0\n",
    "                no_feedback_no_int.append(bsdict)\n",
    "            elif data['nx'][0] != 0 and data['ny'][0] == 0:\n",
    "                just_mrna_feedback.append(bsdict)\n",
    "            elif data['nx'][0] == 0 and data['ny'][0] != 0:\n",
    "                just_protein_feedback.append(bsdict)\n",
    "            else:\n",
    "                both_feedback.append(bsdict)\n",
    "    print(f\"Finished {parent}\")\n",
    "for i,dataset in enumerate([no_feedback_no_int,just_mrna_feedback,just_protein_feedback,both_feedback]):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.set_index(['fileN','fileda','filedb','sysname'],inplace=True)\n",
    "    df[paramlist+['E[<F_x>]','E[<F_y>]','F_y at avg','F_x at avg','consistent fy signs (avg)','consistent fx signs (avg)',\n",
    "                  'consistent fy signs (at avg)','consistent fx signs (at avg)']].to_csv(f'Data/parameters/{names[i]}.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#To generate the data for the plots\n",
    "for parent in parentfolders:\n",
    "    folders = glob.glob(f'Data/{parent}/*/*')\n",
    "    dat = []\n",
    "    failedsims = []\n",
    "    bootstrapdicts = []\n",
    "    for i,folder in enumerate(folders):\n",
    "        files = glob.glob(folder+'/*data.csv',recursive=True)\n",
    "        for j,f in enumerate(files):\n",
    "            data = pd.read_csv(f)\n",
    "            data = data.reset_index().rename(columns={'index':'perturbation'})\n",
    "            numstrings = f.split(\"_\")[-2].split('n')\n",
    "            if (data[['Cov Bal xx','Cov Bal yy','Cov Bal xy']] > 0.05).any(axis=1).any():\n",
    "                failedsims.append(f)\n",
    "                continue\n",
    "            data['fileN'] = float(numstrings[0])\n",
    "            data['fileda'] = float(numstrings[1])\n",
    "            data['filedb'] = float(numstrings[2])\n",
    "            data['sysname'] = \"/\".join(f.split(\"/\")[:-1])\n",
    "            if 'offset' not in data:\n",
    "                data['offset'] = 0\n",
    "            dat.append(data)\n",
    "            bsdict = bsf.pertexp_interpret(data,'all')\n",
    "            fys = sensitivty_y(data['<x>'].astype(float),data['<y>'].astype(float),\n",
    "                                            data['lambda'],data['nx'].astype(float),data['Kx'],\n",
    "                                            data['ny'].astype(float),data['Ky'],data['offset'])\n",
    "            fxs = sensitivty_x(data['<x>'].astype(float),data['<y>'].astype(float),\n",
    "                                            data['lambda'],data['nx'].astype(float),data['Kx'],\n",
    "                                            data['ny'].astype(float),data['Ky'],data['offset'])\n",
    "            bsdict['F_y at avg'] = fys.mean()\n",
    "            bsdict['F_x at avg'] = fxs.mean()\n",
    "            bsdict['consistent fy signs (avg)'] = np.sum(np.sign(data['<F_y>']))\n",
    "            bsdict['consistent fx signs (avg)'] = np.sum(np.sign(1-data['<F_x>']))\n",
    "            bsdict['consistent fy signs (at avg)'] = np.sum(np.sign(fys))\n",
    "            bsdict['consistent fx signs (at avg)'] = np.sum(np.sign(1-fxs))\n",
    "            bsdict['fileN'] = float(numstrings[0])\n",
    "            bsdict['fileda'] = float(numstrings[1])\n",
    "            bsdict['filedb'] = float(numstrings[2])\n",
    "            bsdict['sysname'] = \"/\".join(f.split(\"/\")[:-1])\n",
    "            for p in paramlist:\n",
    "                try:\n",
    "                    bsdict[p] = data[p][0]\n",
    "                except KeyError:\n",
    "                    bsdict[p] = 0\n",
    "            bootstrapdicts.append(bsdict)\n",
    "    directory = f\"/\".join(f.split(\"/\")[:-3])\n",
    "    bootstrapped_res = pd.DataFrame(bootstrapdicts)\n",
    "    bootstrapped_res.set_index([\"fileN\",'fileda','filedb','sysname'],inplace=True)\n",
    "    bootstrapped_res[standard_columns].to_csv(f'{directory}/{directory.split(\"/\")[-1]}_standard_form.csv')\n",
    "    print(f\"Finished {directory}\")\n",
    "    with open(f'{directory}/{directory.split(\"/\")[-1]}_failedsims.txt','w') as f:\n",
    "        for path in failedsims:\n",
    "            f.write(f\"{path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci_comp0624",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
